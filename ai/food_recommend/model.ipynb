{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**นายพชรพล เกตุแก้ว รหัสนักศึกษา 6610110190**\n",
        "# Food Classification from Text Using CNN\n",
        "- โมเดลจำแนกอาหารจากข้อความ"
      ],
      "metadata": {
        "id": "QaouwJjYxH9f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "AswPz_IhyRFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 1 นำเข้าไลบารี่ต่างๆที่จำเป็น"
      ],
      "metadata": {
        "id": "CWyNBfBfySBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import pickle\n"
      ],
      "metadata": {
        "id": "a0hKIHRKydm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 2 เตรียมข้อมูลข้อความสำหรับฝึกโมเดล"
      ],
      "metadata": {
        "id": "4k5wwlSIyxsY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดชุดข้อมูลและแสดงข้อมูลพื้นฐาน\n",
        "df = pd.read_csv(\"/content/food_recommendation_dataset.csv\")\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"\\nClass distribution:\")\n",
        "print(df['label'].value_counts())\n",
        "print(\"\\nSample data:\")\n",
        "print(df.head())\n",
        "\n",
        "# ทำความสะอาดข้อความ: แปลงเป็นตัวพิมพ์เล็ก ลบอักขระที่ไม่ใช่ตัวอักษร และตัดช่องว่าง\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "df = df[df['text'] != '']  # ลบแถวที่ข้อความว่างหลังทำความสะอาด\n",
        "\n",
        "# แยกตัวแปรอิสระ (ข้อความ) และตัวแปรเป้าหมาย (ป้ายกำกับ)\n",
        "X = df['text'].values\n",
        "y = df['label'].values\n",
        "\n",
        "# แบ่งข้อมูลเป็นชุดฝึก (80%) และชุดตรวจสอบ (20%) โดยคงสัดส่วนแต่ละคลาส\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gdR3379SqoEO",
        "outputId": "275187d2-a2bc-4ef6-a3ae-7da845c151ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total samples: 4575\n",
            "\n",
            "Class distribution:\n",
            "label\n",
            "sushi        915\n",
            "hamburger    915\n",
            "pizza        915\n",
            "ice_cream    915\n",
            "apple_pie    915\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Sample data:\n",
            "                                                text      label\n",
            "0  I want small, delicate bites with bold umami f...      sushi\n",
            "1  I want a sandwich with a juicy patty between t...  hamburger\n",
            "2  I want a sandwich with a juicy patty between t...  hamburger\n",
            "3  I want layers of bread, meat, veggies, and con...  hamburger\n",
            "4  Honestly, cheesy, saucy, and satisfying comfor...      pizza\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- โหลดชุดข้อมูลจากไฟล์ CSV และแสดงจำนวนตัวอย่าง การกระจายของแต่ละหมวดอาหาร และตัวอย่างข้อมูลดิบ  \n",
        "- ทำความสะอาดข้อความโดยแปลงเป็นตัวพิมพ์เล็ก ลบเครื่องหมายวรรคตอน/ตัวเลข และตัดช่องว่างส่วนเกิน เพื่อให้ข้อมูลพร้อมสำหรับการประมวลผลด้วยโมเดล NLP  \n",
        "- ลบแถวที่กลายเป็นข้อความว่างหลังการทำความสะอาด เพื่อหลีกเลี่ยงข้อมูลเสีย  \n",
        "- แบ่งข้อมูลออกเป็นชุดฝึกและชุดตรวจสอบโดยใช้ `train_test_split` แบบ stratified เพื่อรักษาสัดส่วนของแต่ละคลาสให้เท่ากันทั้งสองชุด ซึ่งช่วยให้การประเมินโมเดลมีความน่าเชื่อถือ"
      ],
      "metadata": {
        "id": "aobXGTaL5MOR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 3 แปลงข้อความและป้ายกำกับให้อยู่ในรูปแบบที่โมเดลเข้าใจ"
      ],
      "metadata": {
        "id": "Gtzc5w4my2RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ตั้งค่าพารามิเตอร์การแปลงข้อความเป็นตัวเลข\n",
        "MAX_WORDS = 10000\n",
        "MAX_LEN = 50\n",
        "\n",
        "# สร้างและฝึกตัวตัดคำ (tokenizer) จากชุดฝึก\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "# แปลงข้อความเป็นลำดับตัวเลข\n",
        "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
        "X_val_seq = tokenizer.texts_to_sequences(X_val)\n",
        "\n",
        "# ปรับความยาวของทุกลำดับให้เท่ากันด้วย padding\n",
        "X_train_pad = pad_sequences(X_train_seq, maxlen=MAX_LEN, padding='post')\n",
        "X_val_pad = pad_sequences(X_val_seq, maxlen=MAX_LEN, padding='post')\n",
        "\n",
        "# แปลงป้ายกำกับข้อความให้เป็นตัวเลข\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_enc = label_encoder.fit_transform(y_train)\n",
        "y_val_enc = label_encoder.transform(y_val)\n",
        "\n",
        "# แปลงป้ายกำกับตัวเลขให้เป็น one-hot encoding\n",
        "num_classes = len(label_encoder.classes_)\n",
        "y_train_cat = to_categorical(y_train_enc, num_classes)\n",
        "y_val_cat = to_categorical(y_val_enc, num_classes)"
      ],
      "metadata": {
        "id": "XB4PNbgxq0jv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- สร้างตัวตัดคำ (Tokenizer) ที่จำกัดคำศัพท์สูงสุด 10,000 คำ และกำหนดโทเค็นพิเศษ `<OOV>` สำหรับคำที่ไม่อยู่ในพจนานุกรม  \n",
        "- แปลงข้อความในชุดฝึกและชุดตรวจสอบให้เป็นลำดับตัวเลข (sequences) ตามพจนานุกรมที่ได้จากชุดฝึก  \n",
        "- ปรับความยาวของทุกลำดับให้เท่ากัน (50 โทเค็น) โดยเติมศูนย์ด้านหลัง (post-padding) เพื่อให้เหมาะกับการป้อนเข้าโมเดล  \n",
        "- แปลงป้ายกำกับประเภทอาหาร (เช่น 'pizza', 'sushi') ให้เป็นตัวเลขด้วย `LabelEncoder`  \n",
        "- แปลงป้ายกำกับตัวเลขให้เป็นรูปแบบ one-hot encoding เพื่อใช้ในการฝึกโมเดลจำแนกหลายคลาสด้วย categorical crossentropy loss"
      ],
      "metadata": {
        "id": "FQSciu_V5eXD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 4 สร้างและฝึกโมเดล"
      ],
      "metadata": {
        "id": "leFY5Ld9zHRB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# กำหนดพารามิเตอร์และสร้างโมเดล\n",
        "VOCAB_SIZE = min(MAX_WORDS, len(tokenizer.word_index) + 1)\n",
        "EMBEDDING_DIM = 100\n",
        "\n",
        "model = Sequential([\n",
        "    Embedding(VOCAB_SIZE, EMBEDDING_DIM, input_length=MAX_LEN),\n",
        "    Conv1D(128, 5, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    GlobalMaxPooling1D(),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.5),\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# คอมไพล์โมเดลด้วย optimizer, loss function และ metric ที่เหมาะสม\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# แสดงโครงสร้างโมเดล\n",
        "model.summary()\n",
        "\n",
        "# ตั้งค่า early stopping เพื่อหยุดการฝึกเมื่อไม่ปรับปรุง\n",
        "early_stop = EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True)\n",
        "\n",
        "# ฝึกโมเดล\n",
        "history = model.fit(\n",
        "    X_train_pad, y_train_cat,\n",
        "    batch_size=32,\n",
        "    epochs=30,\n",
        "    validation_data=(X_val_pad, y_val_cat),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "IPUaCyriq3Pk",
        "outputId": "4aedc16c-1007-4dc8-9568-cf4f40860227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MAX_WORDS' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-927558219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregularizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0ml2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mVOCAB_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MAX_WORDS' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- สร้างโมเดล Sequential แบบ 1D-CNN สำหรับงานจำแนกข้อความ โดยเริ่มจากชั้น Embedding เพื่อแปลงคำเป็นเวกเตอร์ความหมาย  \n",
        "- ใช้ชั้น Conv1D พร้อม L2 regularization เพื่อดึงคุณลักษณะสำคัญจากลำดับคำ ตามด้วย GlobalMaxPooling1D เพื่อลดมิติ  \n",
        "- เพิ่มชั้น Dense พร้อม regularization และ Dropout เพื่อลด overfitting และเพิ่มความสามารถทั่วไปของโมเดล  \n",
        "- คอมไพล์โมเดลด้วย optimizer ‘adam’ และ loss function ‘categorical_crossentropy’ ซึ่งเหมาะสมกับงานจำแนกหลายคลาส  \n",
        "- ฝึกโมเดลด้วย batch size 32 เป็นเวลาสูงสุด 30 epochs โดยใช้ early stopping ที่ตรวจสอบความแม่นยำบนชุดตรวจสอบ และคืนน้ำหนักที่ดีที่สุดเมื่อหยุดฝึก  \n",
        "- บันทึกประวัติการฝึก (history) เพื่อใช้วิเคราะห์ประสิทธิภาพโมเดลภายหลัง"
      ],
      "metadata": {
        "id": "5i28SnBE59_g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 5 ประเมินผลและตรวจสอบเป้าหมายความแม่นยำของโมเดล"
      ],
      "metadata": {
        "id": "miOBOM5xzKXi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ประเมินผลโมเดลบนชุดตรวจสอบและตรวจสอบเป้าหมายความแม่นยำ\n",
        "val_loss, val_acc = model.evaluate(X_val_pad, y_val_cat, verbose=0)\n",
        "print(f\"\\nValidation Accuracy: {val_acc:.4f} ({val_acc*100:.2f}%)\")\n",
        "\n",
        "# ตรวจสอบว่าโมเดลบรรลุเป้าหมายความแม่นยำ >80% หรือไม่\n",
        "if val_acc >= 0.80:\n",
        "    print(\"เป้าหมาย >80% สำเร็จ!\")\n",
        "else:\n",
        "    print(\"ยังไม่ถึง 80% — อาจต้องปรับ hyperparameter หรือเพิ่มข้อมูล\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZkxskQcq8h1",
        "outputId": "08cbcb42-94a1-4313-c411-ebef4cb41be7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "✅ Validation Accuracy: 1.0000 (100.00%)\n",
            "🎉 เป้าหมาย >80% สำเร็จ!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- ประเมินประสิทธิภาพของโมเดลที่ฝึกเสร็จแล้วบนชุดตรวจสอบ (validation set) โดยใช้ฟังก์ชัน `evaluate()` เพื่อคำนวณค่า loss และความแม่นยำ  \n",
        "- แสดงผลลัพธ์ความแม่นยำเป็นทั้งทศนิยมและเปอร์เซ็นต์ เพื่อให้อ่านเข้าใจง่าย  \n",
        "- ตรวจสอบเงื่อนไขว่าโมเดลบรรลุเป้าหมายความแม่นยำขั้นต่ำที่กำหนดไว้ (80%) หรือไม่ ซึ่งสอดคล้องกับความต้องการของระบบแนะนำเมนูที่ต้องการความแม่นยำสูง  \n",
        "- ให้คำแนะนำเบื้องต้นหากยังไม่ถึงเป้าหมาย เช่น การปรับ hyperparameter หรือขยายชุดข้อมูล เพื่อช่วยในการพัฒนาโมเดลต่อไป"
      ],
      "metadata": {
        "id": "ToTvK1Vd6Ixl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 6 บันทึกโมเดลและส่วนประกอบที่จำเป็นสำหรับการใช้งานจริง\n",
        "\n"
      ],
      "metadata": {
        "id": "D6Mx4DfxzPVe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# บันทึกโมเดลและอ็อบเจกต์ที่จำเป็นสำหรับการ deploy หรือใช้งานในอนาคต\n",
        "model.save(\"/content/food_classifier_model.keras\")\n",
        "\n",
        "with open('/content/tokenizer.pkl', 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open('/content/label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"บันทึกโมเดล, tokenizer, และ label encoder เรียบร้อย!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V93uaBg_q-lu",
        "outputId": "2b489137-20bb-4bc0-f842-b60dc898b609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ บันทึกโมเดล, tokenizer, และ label encoder เรียบร้อย!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- บันทึกโมเดลที่ฝึกเสร็จแล้วในรูปแบบไฟล์ `.keras` ซึ่งสามารถโหลดกลับมาใช้ใหม่ได้ทันทีโดยไม่ต้องฝึกซ้ำ  \n",
        "- บันทึก `tokenizer` ที่ใช้แปลงข้อความเป็นตัวเลข ลงในไฟล์ pickle เพื่อให้ระบบใหม่สามารถประมวลผลข้อความด้วยพจนานุกรมเดียวกัน  \n",
        "- บันทึก `label_encoder` ที่เก็บ mapping ระหว่างชื่อหมวดอาหาร (เช่น 'pizza') กับตัวเลข index เพื่อแปลงผลลัพธ์จากโมเดลกลับเป็นชื่ออาหารที่อ่านเข้าใจได้  \n",
        "- ยืนยันการบันทึกสำเร็จผ่านข้อความแสดงผล ซึ่งเป็นขั้นตอนสำคัญก่อนนำไป deploy ผ่าน FastAPI หรือใช้ในระบบแนะนำเมนูต่อไป"
      ],
      "metadata": {
        "id": "-oCx2wIx6TRG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 7 ทดสอบการทำนายประเภทอาหารจากข้อความใหม่\n",
        "\n"
      ],
      "metadata": {
        "id": "YbgqDsgLzQHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ฟังก์ชันทำนายประเภทอาหารจากข้อความใหม่\n",
        "def predict_food(text):\n",
        "    cleaned = clean_text(text)\n",
        "    seq = tokenizer.texts_to_sequences([cleaned])\n",
        "    pad = pad_sequences(seq, maxlen=MAX_LEN, padding='post')\n",
        "    pred = model.predict(pad, verbose=0)\n",
        "    label_idx = np.argmax(pred, axis=1)[0]\n",
        "    food = label_encoder.inverse_transform([label_idx])[0]\n",
        "    confidence = np.max(pred)\n",
        "    return food, confidence\n",
        "\n",
        "# ตัวอย่างข้อความทดสอบเพื่อประเมินความสามารถการทำนาย\n",
        "test_texts = [\n",
        "    \"I want something cold and sweet with chocolate sauce\",\n",
        "    \"A food with crust, sauce, and melted cheese on top\",\n",
        "    \"Something with pepperoni and melted cheese layers\",\n",
        "    \"I'm craving a juicy beef patty in a soft bun\",\n",
        "    \"Something with bread on top and bottom, meat in between\",\n",
        "    \"Fast food that comes with fries on the side\",\n",
        "    \"A handheld meal with cheese, lettuce, and tomato\",\n",
        "    \"A layered dish with sauce, vegetables, and meat\",\n",
        "    \"Something you can eat quickly with one hand\",\n",
        "    \"I’d love something grilled and juicy between buns\",\n",
        "]\n",
        "\n",
        "# ทดสอบการทำนายและแสดงผลลัพธ์พร้อมระดับความมั่นใจ\n",
        "for t in test_texts:\n",
        "    food, conf = predict_food(t)\n",
        "    print(f\"Input: '{t}' → Predicted: {food} (Confidence: {conf:.2f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EzZNFKfq_yL",
        "outputId": "c78579e1-6dab-4069-e52d-c409c2a06b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: 'I want something cold and sweet with chocolate sauce' → Predicted: ice_cream (Confidence: 0.98)\n",
            "Input: 'A cold dessert that melts in the mouth would be nice' → Predicted: ice_cream (Confidence: 0.97)\n",
            "Input: 'Something creamy and chilled for a hot day' → Predicted: ice_cream (Confidence: 0.29)\n",
            "Input: 'I’d love a sweet treat that comes in a cone or cup' → Predicted: ice_cream (Confidence: 0.99)\n",
            "Input: 'Maybe something frozen with vanilla and strawberry flavors' → Predicted: ice_cream (Confidence: 0.48)\n",
            "Input: 'A dessert that cools me down instantly' → Predicted: apple_pie (Confidence: 0.45)\n",
            "Input: 'I’m thinking of something that melts if you don’t eat it fast' → Predicted: ice_cream (Confidence: 0.99)\n",
            "Input: 'A cold snack that makes me feel refreshed' → Predicted: ice_cream (Confidence: 0.75)\n",
            "Input: 'Something icy and smooth after dinner' → Predicted: ice_cream (Confidence: 0.80)\n",
            "Input: 'Something sweet and cold, maybe with sprinkles' → Predicted: pizza (Confidence: 0.44)\n",
            "Input: 'Fresh raw fish on vinegared rice sounds perfect' → Predicted: sushi (Confidence: 0.95)\n",
            "Input: 'I’m in the mood for something Japanese and delicate' → Predicted: sushi (Confidence: 0.92)\n",
            "Input: 'Small bites of rice with seafood on top sound nice' → Predicted: sushi (Confidence: 0.94)\n",
            "Input: 'Something that goes well with soy sauce and wasabi' → Predicted: sushi (Confidence: 0.99)\n",
            "Input: 'I’d love something with seaweed wrapping and fish inside' → Predicted: sushi (Confidence: 0.94)\n",
            "Input: 'Cold, fresh, bite-sized food from Japan sounds great' → Predicted: sushi (Confidence: 0.94)\n",
            "Input: 'Something that feels light but flavorful, maybe with salmon' → Predicted: pizza (Confidence: 0.44)\n",
            "Input: 'I’m craving something that’s usually eaten with chopsticks' → Predicted: sushi (Confidence: 0.82)\n",
            "Input: 'Fish and rice together, simple but elegant' → Predicted: sushi (Confidence: 0.97)\n",
            "Input: 'A dish served on a wooden tray with wasabi on the side' → Predicted: sushi (Confidence: 0.49)\n",
            "Input: 'I’d love something with melted cheese on crispy dough' → Predicted: pizza (Confidence: 0.94)\n",
            "Input: 'Hot food straight from the oven with tomato sauce and cheese' → Predicted: pizza (Confidence: 0.92)\n",
            "Input: 'Something Italian with toppings and stretchy cheese' → Predicted: pizza (Confidence: 0.98)\n",
            "Input: 'Maybe a round dish sliced into triangles to share with friends' → Predicted: pizza (Confidence: 0.97)\n",
            "Input: 'I want something baked with mozzarella and sauce' → Predicted: pizza (Confidence: 0.43)\n",
            "Input: 'Something perfect to eat while watching a movie' → Predicted: hamburger (Confidence: 0.30)\n",
            "Input: 'Cheesy, savory, and baked to perfection' → Predicted: pizza (Confidence: 0.41)\n",
            "Input: 'Something that comes in a box and smells amazing' → Predicted: pizza (Confidence: 0.77)\n",
            "Input: 'A food with crust, sauce, and melted cheese on top' → Predicted: pizza (Confidence: 0.56)\n",
            "Input: 'Something with pepperoni and melted cheese layers' → Predicted: pizza (Confidence: 0.46)\n",
            "Input: 'I'm craving a juicy beef patty in a soft bun' → Predicted: hamburger (Confidence: 0.99)\n",
            "Input: 'Something with bread on top and bottom, meat in between' → Predicted: sushi (Confidence: 0.32)\n",
            "Input: 'Fast food that comes with fries on the side' → Predicted: hamburger (Confidence: 0.39)\n",
            "Input: 'A handheld meal with cheese, lettuce, and tomato' → Predicted: hamburger (Confidence: 0.58)\n",
            "Input: 'A layered dish with sauce, vegetables, and meat' → Predicted: pizza (Confidence: 0.59)\n",
            "Input: 'Something you can eat quickly with one hand' → Predicted: hamburger (Confidence: 0.98)\n",
            "Input: 'I’d love something grilled and juicy between buns' → Predicted: hamburger (Confidence: 0.88)\n",
            "Input: 'A quick bite that fills me up instantly' → Predicted: hamburger (Confidence: 0.66)\n",
            "Input: 'Warm, savory, and satisfying — maybe with cheese' → Predicted: pizza (Confidence: 0.89)\n",
            "Input: 'A meal that comes wrapped in paper and smells amazing' → Predicted: hamburger (Confidence: 0.51)\n",
            "Input: 'A warm dessert with apples and cinnamon sounds comforting' → Predicted: apple_pie (Confidence: 0.90)\n",
            "Input: 'I want something baked with a crispy crust and soft inside' → Predicted: pizza (Confidence: 0.94)\n",
            "Input: 'A sweet treat that smells like home when it’s in the oven' → Predicted: apple_pie (Confidence: 0.97)\n",
            "Input: 'Something fruity and warm that goes well with tea' → Predicted: sushi (Confidence: 0.47)\n",
            "Input: 'A dessert that’s golden brown and filled with fruit' → Predicted: apple_pie (Confidence: 0.49)\n",
            "Input: 'Sweet and slightly tangy, maybe with baked apples' → Predicted: apple_pie (Confidence: 0.41)\n",
            "Input: 'Something that’s great with vanilla ice cream on top' → Predicted: ice_cream (Confidence: 0.34)\n",
            "Input: 'A baked dessert with a buttery crust and apple filling' → Predicted: apple_pie (Confidence: 0.99)\n",
            "Input: 'A sweet dish that reminds me of cozy evenings' → Predicted: apple_pie (Confidence: 0.59)\n",
            "Input: 'Something with cinnamon, apples, and flaky pastry' → Predicted: apple_pie (Confidence: 0.85)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- สร้างฟังก์ชัน `predict_food()` ที่รับข้อความเข้ามา แล้วผ่านกระบวนการเดียวกับชุดฝึก: ทำความสะอาดข้อความ → แปลงเป็นลำดับตัวเลข → ปรับความยาว → ทำนายด้วยโมเดล  \n",
        "- ใช้ `argmax` เพื่อหาดัชนีของหมวดอาหารที่มีคะแนนความน่าจะเป็นสูงสุด และแปลงกลับเป็นชื่ออาหารด้วย `label_encoder.inverse_transform()`  \n",
        "- คำนวณระดับความมั่นใจ (confidence) จากค่าความน่าจะเป็นสูงสุดของการทำนาย  \n",
        "- ทดสอบฟังก์ชันกับชุดข้อความตัวอย่างที่เขียนในรูปแบบโดยนัย (ไม่เอ่ยชื่ออาหารตรงๆ) เพื่อประเมินว่าโมเดลเข้าใจบริบทได้ดีเพียงใด  \n",
        "- แสดงผลลัพธ์การทำนายพร้อมระดับความมั่นใจ เพื่อให้เห็นภาพชัดเจนว่าโมเดลสามารถใช้งานจริงในระบบแนะนำเมนูได้หรือไม่"
      ],
      "metadata": {
        "id": "SWkzkti86bgJ"
      }
    }
  ]
}