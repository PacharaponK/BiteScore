{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**นายพชรพล เกตุแก้ว รหัสนักศึกษา 6610110190**\n",
        "# Food101-5: Lightweight Food Image Classifier Using MobileNetV2\n",
        "- โมเดลจำแนกอาหาร 5 ชนิด\n"
      ],
      "metadata": {
        "id": "C_Q061iJPEVM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "6fiFAAeXx-JD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 1 นำเข้าไลบารี่ต่างๆที่จำเป็น"
      ],
      "metadata": {
        "id": "LmHC3MctPxSG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoNK6YddqbfG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "โดยส่วนที่สำคัญสำหรับขั้นตอนนี้คือ การนำเข้าไลบารี่ต่างๆจาก tensirflow.keras ได้แก่\n",
        "\n",
        "- **layers, models** -> ใช้สร้างชั้น (layer) ต่าง ๆ ของโมเดลและสร้างโครงสร้างโมเดล\n",
        "- **.preprocessing.image**\n",
        "  - **ImageDataGenerator** -> ใช้สร้าง data augmentation และโหลดภาพจากโฟลเดอร์เป็น batch โดยอัตโนมัติ\n",
        "- **.callbacks**\n",
        "  - **EarlyStopping** -> ใช้ในการหยุดฝึกอัตโนมัติหาก validation loss ไม่ดีขึ้นหลังจากผ่าน epoch ที่กำหนด → ป้องกัน overfitting\n",
        "  - **ReduceLROnPlateau** -> ลด learning rate เมื่อ validation loss หยุดลดลง → ช่วยให้โมเดลเรียนรู้ละเอียดขึ้นในช่วงท้าย"
      ],
      "metadata": {
        "id": "B6bf-g9FQdrN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 2 ดาวน์โหลดชุดข้อมูลและการกรอง"
      ],
      "metadata": {
        "id": "zG7TLqr1QQJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ดาวน์โหลด Dataset\n",
        "!wget -nc http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz\n",
        "!tar -xzf food-101.tar.gz\n",
        "\n",
        "# สร้างโฟลเดอร์ Subset\n",
        "subset_dir = \"food101_5class\"\n",
        "os.makedirs(f\"{subset_dir}/train\", exist_ok=True)\n",
        "os.makedirs(f\"{subset_dir}/valid\", exist_ok=True)\n",
        "\n",
        "TOP_5_CLASSES = ['apple_pie', 'pizza', 'hamburger', 'sushi', 'ice_cream']\n",
        "\n",
        "# สร้างโฟลเดอร์ย่อยแต่ละ Class\n",
        "for cls in TOP_5_CLASSES:\n",
        "    os.makedirs(f\"{subset_dir}/train/{cls}\", exist_ok=True)\n",
        "    os.makedirs(f\"{subset_dir}/valid/{cls}\", exist_ok=True)\n",
        "\n",
        "# อ่านรายการ Train/Test\n",
        "with open(\"food-101/meta/train.txt\") as f:\n",
        "    train_list = [line.strip() for line in f.readlines()]\n",
        "with open(\"food-101/meta/test.txt\") as f:\n",
        "    test_list = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# กรองเฉพาะ 5 class\n",
        "train_filtered = [item for item in train_list if item.split('/')[0] in TOP_5_CLASSES]\n",
        "valid_filtered = [item for item in test_list if item.split('/')[0] in TOP_5_CLASSES]\n",
        "\n",
        "# คัดลอกไฟล์\n",
        "for item in train_filtered:\n",
        "    src = f\"food-101/images/{item}.jpg\"\n",
        "    dst = f\"{subset_dir}/train/{item}.jpg\"\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "for item in valid_filtered:\n",
        "    src = f\"food-101/images/{item}.jpg\"\n",
        "    dst = f\"{subset_dir}/valid/{item}.jpg\"\n",
        "    os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
        "    shutil.copy(src, dst)\n",
        "\n",
        "print(\"สร้าง subset 5 class เสร็จสิ้น!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rxuY7Uks0eq",
        "outputId": "5b19f91c-d087-4ab5-b548-921a159421b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File ‘food-101.tar.gz’ already there; not retrieving.\n",
            "\n",
            "สร้าง subset 5 class เสร็จสิ้น!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ส่วนของขั้นตอนนี้ทำหน้าที่\n",
        "- ดาวน์โหลดข้อมูลจาก http://data.vision.ee.ethz.ch/cvl/food-101.tar.gz และแตกไฟล์\n",
        "- จากนั้นสร้างโฟลเดอร์ที่มีชุดฝึกกับชุดทดลอง จากนั้นอ่านไฟล์ meta เผื่อกรองเอาเฉพาะ 5 class ที่เราเลือกมา\n",
        "- สุดท้ายทำการคัดลอกไฟล์ต่างๆที่เราได้กรองมาจากใน meta มาไว้ในชุดฝึกและชุดทดลอง\n",
        "- และแสดงผล \"สร้าง subset 5 class เสร็จสิ้น!\" เมื่อสำเร็จ"
      ],
      "metadata": {
        "id": "RtC9pv6eTcSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# กำหนดพารามิเตอร์พื้นฐานสำหรับการประมวลผลภาพ\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# ปรับสเกลค่าพิกเซล + data augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2\n",
        ")\n",
        "\n",
        "# ปรับสเกลค่าพิกเซลเท่านั้น\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# สร้างข้อมูลสำหรับชุดฝึกจากโฟลเดอร์\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    f\"{subset_dir}/train\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# สร้างข้อมูลสำหรับชุดตรวจสอบจากโฟลเดอร์\n",
        "val_gen = val_datagen.flow_from_directory(\n",
        "    f\"{subset_dir}/valid\",\n",
        "    batch_size=BATCH_SIZE,\n",
        "    target_size=(224, 224),\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# แสดง mapping ของ class\n",
        "print(train_gen.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okMd2-Epucbd",
        "outputId": "eb9092e8-a15f-4214-97ca-173365cf571f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 3750 images belonging to 5 classes.\n",
            "Found 1250 images belonging to 5 classes.\n",
            "{'apple_pie': 0, 'hamburger': 1, 'ice_cream': 2, 'pizza': 3, 'sushi': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ส่วนของขั้นตอนนี้ทำหน้าที่\n",
        "- กำหนดขนาดแบตช์เป็น 32 และตั้งค่า ImageDataGenerator สำหรับชุดฝึกให้ปรับสเกลค่าพิกเซลและเพิ่มความหลากหลายของข้อมูลด้วยการแปลงภาพ (data augmentation) เช่น หมุน เลื่อน พลิก และซูม\n",
        "- ตั้งค่า ImageDataGenerator สำหรับชุดตรวจสอบให้ปรับสเกลค่าพิกเซลเท่านั้น โดยไม่มีการแปลงภาพเพิ่ม\n",
        "- สร้างตัวสร้างข้อมูล (generator) สำหรับชุดฝึกและชุดตรวจสอบโดยอ่านภาพตรงจากโฟลเดอร์ย่อยของแต่ละคลาสอัตโนมัติ\n",
        "- แสดง mapping ระหว่างชื่อคลาสกับ Index ที่โมเดลจะใช้ในการทำนาย เพื่อให้รู้ลำดับของแต่ละหมวดอาหาร"
      ],
      "metadata": {
        "id": "4R1xSk9xWy57"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 3 สร้างและฝึกโมเดลจำแนกอาหารด้วย Transfer Learning"
      ],
      "metadata": {
        "id": "Wre8aPm_JVS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดโมเดล MobileNetV2\n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "base_model.trainable = False\n",
        "\n",
        "# สร้างโครงสร้างโมเดลใหม่ด้วย Functional API โดยต่อทับบน base_model\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "x = base_model(inputs, training=False)\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dropout(0.3)(x)\n",
        "outputs = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "# ประกอบโมเดลสมบูรณ์จาก input ถึง output\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# กำหนด optimizer, loss function และ metrics สำหรับการฝึก\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# ตั้งค่า callbacks สำหรับควบคุมการฝึก: หยุดอัตโนมัติเมื่อไม่ดีขึ้น + ปรับ learning rate\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=8, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(factor=0.5, patience=4, min_lr=1e-7)\n",
        "]\n",
        "\n",
        "# เริ่มฝึกโมเดลโดยใช้ train_gen และ val_gen ที่เตรียมไว้\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=40,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "613Y4mS0ueyn",
        "outputId": "162bcd23-8caf-4fb0-b32e-015bd09d9017"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 652ms/step - accuracy: 0.5617 - loss: 1.1482 - val_accuracy: 0.8728 - val_loss: 0.3784 - learning_rate: 0.0010\n",
            "Epoch 2/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 428ms/step - accuracy: 0.8014 - loss: 0.5645 - val_accuracy: 0.8912 - val_loss: 0.3182 - learning_rate: 0.0010\n",
            "Epoch 3/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 421ms/step - accuracy: 0.8042 - loss: 0.5301 - val_accuracy: 0.8880 - val_loss: 0.3057 - learning_rate: 0.0010\n",
            "Epoch 4/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 416ms/step - accuracy: 0.8087 - loss: 0.5193 - val_accuracy: 0.8936 - val_loss: 0.2844 - learning_rate: 0.0010\n",
            "Epoch 5/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 416ms/step - accuracy: 0.8295 - loss: 0.4746 - val_accuracy: 0.8968 - val_loss: 0.2936 - learning_rate: 0.0010\n",
            "Epoch 6/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 416ms/step - accuracy: 0.8253 - loss: 0.4661 - val_accuracy: 0.8952 - val_loss: 0.3050 - learning_rate: 0.0010\n",
            "Epoch 7/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 426ms/step - accuracy: 0.8414 - loss: 0.4482 - val_accuracy: 0.8944 - val_loss: 0.2733 - learning_rate: 0.0010\n",
            "Epoch 8/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 420ms/step - accuracy: 0.8443 - loss: 0.4410 - val_accuracy: 0.9000 - val_loss: 0.2718 - learning_rate: 0.0010\n",
            "Epoch 9/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 435ms/step - accuracy: 0.8375 - loss: 0.4320 - val_accuracy: 0.8984 - val_loss: 0.2899 - learning_rate: 0.0010\n",
            "Epoch 10/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 427ms/step - accuracy: 0.8570 - loss: 0.3876 - val_accuracy: 0.9056 - val_loss: 0.2715 - learning_rate: 0.0010\n",
            "Epoch 11/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 419ms/step - accuracy: 0.8592 - loss: 0.3921 - val_accuracy: 0.9016 - val_loss: 0.2767 - learning_rate: 0.0010\n",
            "Epoch 12/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 421ms/step - accuracy: 0.8528 - loss: 0.4068 - val_accuracy: 0.9040 - val_loss: 0.2780 - learning_rate: 0.0010\n",
            "Epoch 13/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 428ms/step - accuracy: 0.8626 - loss: 0.3809 - val_accuracy: 0.9080 - val_loss: 0.2707 - learning_rate: 0.0010\n",
            "Epoch 14/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 421ms/step - accuracy: 0.8580 - loss: 0.3675 - val_accuracy: 0.9160 - val_loss: 0.2621 - learning_rate: 0.0010\n",
            "Epoch 15/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 442ms/step - accuracy: 0.8634 - loss: 0.3741 - val_accuracy: 0.9056 - val_loss: 0.2768 - learning_rate: 0.0010\n",
            "Epoch 16/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 428ms/step - accuracy: 0.8678 - loss: 0.3662 - val_accuracy: 0.9104 - val_loss: 0.2621 - learning_rate: 0.0010\n",
            "Epoch 17/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 425ms/step - accuracy: 0.8686 - loss: 0.3714 - val_accuracy: 0.9056 - val_loss: 0.2711 - learning_rate: 0.0010\n",
            "Epoch 18/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 422ms/step - accuracy: 0.8752 - loss: 0.3355 - val_accuracy: 0.9088 - val_loss: 0.2546 - learning_rate: 0.0010\n",
            "Epoch 19/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 423ms/step - accuracy: 0.8765 - loss: 0.3417 - val_accuracy: 0.9104 - val_loss: 0.2625 - learning_rate: 0.0010\n",
            "Epoch 20/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 441ms/step - accuracy: 0.8880 - loss: 0.3081 - val_accuracy: 0.9088 - val_loss: 0.2691 - learning_rate: 0.0010\n",
            "Epoch 21/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 418ms/step - accuracy: 0.8748 - loss: 0.3516 - val_accuracy: 0.9032 - val_loss: 0.2594 - learning_rate: 0.0010\n",
            "Epoch 22/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 422ms/step - accuracy: 0.8840 - loss: 0.3382 - val_accuracy: 0.9008 - val_loss: 0.2677 - learning_rate: 0.0010\n",
            "Epoch 23/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 426ms/step - accuracy: 0.8893 - loss: 0.3208 - val_accuracy: 0.9064 - val_loss: 0.2659 - learning_rate: 5.0000e-04\n",
            "Epoch 24/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 427ms/step - accuracy: 0.9046 - loss: 0.2768 - val_accuracy: 0.9088 - val_loss: 0.2604 - learning_rate: 5.0000e-04\n",
            "Epoch 25/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 418ms/step - accuracy: 0.8957 - loss: 0.2766 - val_accuracy: 0.9032 - val_loss: 0.2743 - learning_rate: 5.0000e-04\n",
            "Epoch 26/40\n",
            "\u001b[1m118/118\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 417ms/step - accuracy: 0.8944 - loss: 0.2822 - val_accuracy: 0.9120 - val_loss: 0.2587 - learning_rate: 5.0000e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- โหลดโมเดลพื้นฐาน MobileNetV2 ที่ผ่านการฝึกมาแล้วบน ImageNet โดยตั้งค่า `include_top=False` เพื่อตัดชั้นสุดท้ายออก และ freeze น้ำหนักทั้งหมดไม่ให้ปรับระหว่างฝึก (Transfer Learning)  \n",
        "- สร้างโครงสร้างโมเดลใหม่ด้วย Functional API โดยต่อชั้นประมวลผลเพิ่มเติมหลัง MobileNetV2 ได้แก่ GlobalAveragePooling2D, Dropout (เพื่อลด overfitting), ชั้น Dense ขนาด 128 ยูนิต และชั้นเอาต์พุตขนาด 5 ยูนิตพร้อม activation แบบ softmax สำหรับจำแนก 5 ชนิดอาหาร  \n",
        "- คอมไพล์โมเดลด้วย optimizer ‘adam’, loss function ‘categorical_crossentropy’ และวัดผลด้วยความแม่นยำ (accuracy)  \n",
        "- กำหนด callbacks สองตัว ได้แก่ EarlyStopping เพื่อหยุดฝึกอัตโนมัติหาก validation loss ไม่ดีขึ้นภายใน 8 epochs และ ReduceLROnPlateau เพื่อลด learning rate เมื่อการเรียนรู้ชะลอตัว  \n",
        "- เริ่มฝึกโมเดลเป็นเวลา 40 epochs โดยใช้ข้อมูลจากตัวสร้างชุดฝึก (`train_gen`) และตรวจสอบกับชุดตรวจสอบ (`val_gen`) แบบ real-time"
      ],
      "metadata": {
        "id": "-cJSPrPkhKCN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 4 ประเมินโมเดล"
      ],
      "metadata": {
        "id": "8Ftq4aSkJvwg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ดึงข้อมูลประวัติการฝึก\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# สร้างกราฟเปรียบเทียบทั้ง Accuracy และ Loss\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# กราฟที่ 1: Accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "# กราฟที่ 2: Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.title('Model Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# --- ประเมินผลเชิงตัวเลข ---\n",
        "print(\"🔍 สรุปผลการฝึกโมเดล:\")\n",
        "print(f\"- ความแม่นยำสูงสุดของชุดฝึก:     {max(acc):.4f} ({max(acc)*100:.2f}%)\")\n",
        "print(f\"- ความแม่นยำสูงสุดของชุดตรวจสอบ: {max(val_acc):.4f} ({max(val_acc)*100:.2f}%)\")\n",
        "\n",
        "# ประเมินโมเดลบนชุดตรวจสอบอีกครั้งเพื่อความแม่นยำสุดท้าย\n",
        "final_loss, final_accuracy = model.evaluate(val_gen, verbose=0)\n",
        "print(f\"\\n✅ ความแม่นยำสุดท้ายบนชุดตรวจสอบ: {final_accuracy:.4f} ({final_accuracy*100:.2f}%)\")\n",
        "\n",
        "# ตรวจสอบว่าผ่านเกณฑ์ >80% หรือไม่\n",
        "if final_accuracy > 0.80:\n",
        "    print(\"🎉 ผ่านเกณฑ์! โมเดลพร้อมสำหรับการ deploy\")\n",
        "else:\n",
        "    print(\"⚠️ ยังไม่ผ่านเกณฑ์ 80% ควรปรับปรุงเพิ่มเติม\")"
      ],
      "metadata": {
        "id": "rOl51nqixiZ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- ดึงข้อมูลประวัติความแม่นยำและค่า loss จากการฝึกโมเดล เพื่อนำมาวิเคราะห์ผล  \n",
        "- สร้างกราฟเปรียบเทียบระหว่างชุดฝึกและชุดตรวจสอบทั้งในด้าน **ความแม่นยำ (Accuracy)** และ **ค่าความสูญเสีย (Loss)** แบบคู่ขนาน เพื่อช่วยตรวจจับปัญหาเช่น overfitting หรือ underfitting  \n",
        "- คำนวณและแสดงค่าความแม่นยำสูงสุดที่โมเดลทำได้ทั้งในชุดฝึกและชุดตรวจสอบ  \n",
        "- ประเมินประสิทธิภาพสุดท้ายของโมเดลด้วย `model.evaluate()` บนชุดตรวจสอบอีกครั้งเพื่อให้ได้ค่าความแม่นยำที่แม่นยำจริง  \n",
        "- ตรวจสอบว่าโมเดลผ่านเกณฑ์เป้าหมายที่กำหนดไว้ (>80%) หรือไม่ เพื่อตัดสินใจว่าพร้อมสำหรับการ deploy หรือยัง"
      ],
      "metadata": {
        "id": "3q0sgv_3K3KH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 5 บันทึกโมเดล"
      ],
      "metadata": {
        "id": "4s9WLECkJ52o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"food_classifier_5class.keras\")\n",
        "print(\"✅ บันทึกโมเดลเรียบร้อย!\")"
      ],
      "metadata": {
        "id": "k7SCI4L6xlR6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ขั้นตอนที่ 6 ทดสอบโมเดล"
      ],
      "metadata": {
        "id": "y2HhqICrJ7mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# นำเข้าไลบรารีที่จำเป็นสำหรับการโหลดโมเดล ประมวลผลภาพ และอัปโหลดไฟล์\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from google.colab import files\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# กำหนดขนาดภาพให้ตรงกับขนาดที่ใช้ฝึกโมเดล\n",
        "IMG_SIZE = 224\n",
        "\n",
        "# โหลดโมเดลที่บันทึกไว้จากไฟล์\n",
        "model = load_model(\"food_classifier_5class.h5\")\n",
        "\n",
        "# อัปโหลดภาพจากผู้ใช้ผ่าน Google Colab\n",
        "uploaded = files.upload()\n",
        "img_path = list(uploaded.keys())[0]\n",
        "\n",
        "# โหลดและประมวลผลภาพให้พร้อมสำหรับการทำนาย\n",
        "img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))\n",
        "img_array = image.img_to_array(img) / 255.0\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# ทำนายคลาสของภาพด้วยโมเดล\n",
        "pred = model.predict(img_array)\n",
        "class_idx = np.argmax(pred)\n",
        "confidence = pred[0][class_idx]\n",
        "class_names = list(train_gen.class_indices.keys())\n",
        "predicted_label = class_names[class_idx]\n",
        "\n",
        "# แสดงผลลัพธ์การทำนายทางคอนโซล\n",
        "print(f\"🔍 ทำนาย: {predicted_label}\")\n",
        "print(f\"📊 ความมั่นใจ: {confidence:.2%}\")\n",
        "\n",
        "# แสดงภาพพร้อมป้ายชื่อผลการทำนาย\n",
        "plt.imshow(img)\n",
        "plt.title(f\"Prediction: {predicted_label} ({confidence:.2%})\")\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9pgwVx73xnsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ในส่วนของขั้นตอนนี้ทำหน้าที่  \n",
        "- โหลดโมเดลที่บันทึกไว้จากไฟล์เพื่อนำมาใช้ทำนายภาพใหม่  \n",
        "- อนุญาตให้ผู้ใช้อัปโหลดภาพผ่านอินเทอร์เฟซของ Google Colab  \n",
        "- โหลดและประมวลผลภาพที่อัปโหลดให้มีขนาดตรงกับที่โมเดลถูกฝึกมา (224×224 พิกเซล) พร้อมปรับสเกลค่าพิกเซลให้อยู่ในช่วง 0–1  \n",
        "- แปลงภาพให้อยู่ในรูปแบบ batch ที่โมเดลรับได้ แล้วทำการทำนายคลาสของภาพ  \n",
        "- ดึงชื่อหมวดอาหารจาก mapping ที่ได้จากชุดฝึก และแสดงผลลัพธ์การทำนายพร้อมระดับความมั่นใจเป็นเปอร์เซ็นต์  \n",
        "- แสดงภาพที่อัปโหลดพร้อมป้ายชื่อผลการทำนายบนกราฟิกเพื่อให้เห็นผลลัพธ์อย่างชัดเจน"
      ],
      "metadata": {
        "id": "eo7_IU4yNdRj"
      }
    }
  ]
}